<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Chapter-6 Deep Learning for Coders with FastAI & Pytorch | Ravi Chandra Veeramachaneni</title><meta name=keywords content><meta name=description content="Multi Label Classification"><meta name=author content="Ravi Chandra Veeramachaneni"><link rel=canonical href=//r-c.ai/blogs/b5/ch6-dl-for-coders/><link crossorigin=anonymous href=/assets/css/stylesheet.min.3a8b00d8b9704de6f4f33d0a113c1892c930ae073602ee85b7c5937497c98078.css integrity="sha256-OosA2LlwTeb08z0KETwYkskwrgc2Au6Ft8WTdJfJgHg=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.2840b7fccd34145847db71a290569594bdbdb00047097f75d6495d162f5d7dff.js integrity="sha256-KEC3/M00FFhH23GikFaVlL29sABHCX911kldFi9dff8=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=//r-c.ai/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=//r-c.ai/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=//r-c.ai/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=//r-c.ai/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=//r-c.ai/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-B5ZRHBFS10"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-B5ZRHBFS10",{anonymize_ip:!1})}</script><meta property="og:title" content="Chapter-6 Deep Learning for Coders with FastAI & Pytorch"><meta property="og:description" content="Multi Label Classification"><meta property="og:type" content="article"><meta property="og:url" content="//r-c.ai/blogs/b5/ch6-dl-for-coders/"><meta property="og:image" content="//r-c.ai/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="blogs"><meta property="article:published_time" content="2021-07-28T00:00:00+00:00"><meta property="article:modified_time" content="2021-07-28T00:00:00+00:00"><meta property="og:site_name" content="RaviChandraVeeramachaneni"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="//r-c.ai/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Chapter-6 Deep Learning for Coders with FastAI & Pytorch"><meta name=twitter:description content="Multi Label Classification"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blogs","item":"//r-c.ai/blogs/"},{"@type":"ListItem","position":2,"name":"Chapter-6 Deep Learning for Coders with FastAI \u0026 Pytorch","item":"//r-c.ai/blogs/b5/ch6-dl-for-coders/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Chapter-6 Deep Learning for Coders with FastAI \u0026 Pytorch","name":"Chapter-6 Deep Learning for Coders with FastAI \u0026 Pytorch","description":"Multi Label Classification","keywords":[],"articleBody":"Keypoints Multi-label classification  Multi-label classification refers to the problem of identifying the categories of objects in images that may not contain exactly one type of object. There may be more than one kind of object, or there may be no objects at all in the classes that you are looking for. See two examples below where we have a bear dataset with a dog included named bear and another example where the cat is classified as cat and horse.   As a note, in FastAI we can handle the multi-labels with MultiCategoryBlock which will encode all the vocabulary into a list of 0’s and have 1s where data is present. So, by checking where 1’s are we can identify which category(s) that image belongs to. This technique of representing the data in 1’s on a vector of 0s is called One-hot encoding.  Binary Cross-Entropy Loss  In the case of single category labels, we have the cross-entropy loss. The Cross-Entropy loss is a combination of using the negative log likelihood on the log values of the probabilities from the softmax function. But in the case of multi-category labels, we don’t have the probabilities rather we have the one-hot encoded values. In this case, the best option would be the binary cross-entropy loss which is basically just mnist_loss along with log.  1 2 3  def binary_cross_entropy(inputs, targets):  inputs = inputs.sigmoid()  return -torch.where(targets==1, 1-inputs, inputs).log().mean()    So, once we are ready with the data and preparing to create Learner for training, we do not need to explicitly provide the loss. The FastAI will pick up the binary corss-entorpy loss by default. Now that we have the loss ready, we need to pick a metric which is accuracy by default for all the classification problems we worked on. But the accuracy is not a good fit for this problem of multi-label since for each image we could have more than one prediction. So we need to use accuracy_multi with a threshold that will address the problem.   Note: Since the threshold for the accuracy_multi is by default 0.5, we can override the function using the partial function from python.\n Example of the Learner in this case:\n1 2  learn = cnn_learner(dls, resnet50, metrics=partial(accuracy_multi, thresh=0.2)) learn.fine_tune(3, base_lr=3e-3, freeze_epochs=4)   Regression  A regression problem is when the output variable is a real or continuous value, such as “salary” or “weight”. Many different models can be used, the simplest is the linear regression. It tries to fit data with the best hyper-plane which goes through the points.   An image regression problem refers to learning from a dataset where the independent variable is an image, and the dependent variable is one or more floats. And image regression is simply a CNN under the hood. One of the key perspective to consider while building a datablock for regression is to use pointblock instead of a category block since the labels represents coordinates. Another important point to remember while construction the Learner is to provide the y_range=(-1,1) attribute to make sure that we give the range of the rescaled coordinates.  1  learn = cnn_learner(dls, resnet18, y_range=(-1,1))    In the case of the regression problem, the loss that can used is MSELoss (Mean Squared Error loss). The MSE tells you how close a regression line is to a set of points. It does this by taking the distances from the points to the regression line (these distances are the “errors”) and squaring them.  Conclusion  All the problems like single-label classification, multi-label classification \u0026 regression seems to work on basis of same model except for the loss function that changes every time. So, we need to keep an eye on hyper parameters and loss which will effect the results.  ","wordCount":"612","inLanguage":"en","datePublished":"2021-07-28T00:00:00Z","dateModified":"2021-07-28T00:00:00Z","author":{"@type":"Person","name":"Ravi Chandra Veeramachaneni"},"mainEntityOfPage":{"@type":"WebPage","@id":"//r-c.ai/blogs/b5/ch6-dl-for-coders/"},"publisher":{"@type":"Organization","name":"Ravi Chandra Veeramachaneni","logo":{"@type":"ImageObject","url":"//r-c.ai/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=//r-c.ai/ accesskey=h title="Ravi Chandra Veeramachaneni (Alt + H)"><img src=//r-c.ai/images/function.png alt=logo aria-label=logo height=35>Ravi Chandra Veeramachaneni</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=//r-c.ai/blogs/ title=Blogs><span>Blogs</span></a></li><li><a href=//r-c.ai/projects/ title=Projects><span>Projects</span></a></li><li><a href=//r-c.ai/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=//r-c.ai/>Home</a>&nbsp;»&nbsp;<a href=//r-c.ai/blogs/>Blogs</a></div><h1 class=post-title>Chapter-6 Deep Learning for Coders with FastAI & Pytorch</h1><div class=post-description>Multi Label Classification</div><div class=post-meta><span title="2021-07-28 00:00:00 +0000 UTC">July 28, 2021</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Ravi Chandra Veeramachaneni</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#keypoints aria-label=Keypoints>Keypoints</a><ul><li><a href=#multi-label-classification aria-label="Multi-label classification">Multi-label classification</a></li><li><a href=#binary-cross-entropy-loss aria-label="Binary Cross-Entropy Loss">Binary Cross-Entropy Loss</a></li><li><a href=#regression aria-label=Regression>Regression</a></li><li><a href=#conclusion aria-label=Conclusion>Conclusion</a></li></ul></li></ul></div></details></div><div class=post-content><h3 id=keypoints>Keypoints<a hidden class=anchor aria-hidden=true href=#keypoints>#</a></h3><h4 id=multi-label-classification>Multi-label classification<a hidden class=anchor aria-hidden=true href=#multi-label-classification>#</a></h4><ul><li><strong>Multi-label classification</strong> refers to the problem of identifying the categories of objects in images that may not contain exactly one type of object.</li><li>There may be more than one kind of object, or there may be no objects at all in the classes that you are looking for.</li><li>See two examples below where we have a bear dataset with a dog included named bear and another example where the cat is classified as cat and horse.</li></ul><p><img loading=lazy src=/blogs/b5/img1.png alt=img1>
<img loading=lazy src=/blogs/b5/img2.png alt=img2></p><ul><li>As a note, in FastAI we can handle the multi-labels with MultiCategoryBlock which will encode all the vocabulary into a list of 0’s and have 1s where data is present.</li><li>So, by checking where 1’s are we can identify which category(s) that image belongs to.</li><li>This technique of representing the data in 1’s on a vector of 0s is called <strong>One-hot encoding</strong>.</li></ul><h4 id=binary-cross-entropy-loss>Binary Cross-Entropy Loss<a hidden class=anchor aria-hidden=true href=#binary-cross-entropy-loss>#</a></h4><ul><li>In the case of single category labels, we have the cross-entropy loss.</li><li>The Cross-Entropy loss is a combination of using the negative log likelihood on the log values of the probabilities from the softmax function.</li><li>But in the case of multi-category labels, we don’t have the probabilities rather we have the one-hot encoded values.</li><li>In this case, the best option would be the binary cross-entropy loss which is basically just mnist_loss along with log.</li></ul><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>binary_cross_entropy</span>(inputs, targets):
</span></span><span style=display:flex><span>    inputs <span style=color:#f92672>=</span> inputs<span style=color:#f92672>.</span>sigmoid()
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> <span style=color:#f92672>-</span>torch<span style=color:#f92672>.</span>where(targets<span style=color:#f92672>==</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span><span style=color:#f92672>-</span>inputs, inputs)<span style=color:#f92672>.</span>log()<span style=color:#f92672>.</span>mean()
</span></span></code></pre></td></tr></table></div></div><ul><li>So, once we are ready with the data and preparing to create Learner for training, we do not need to explicitly provide the loss. The FastAI will pick up the binary corss-entorpy loss by default.</li><li>Now that we have the loss ready, we need to pick a metric which is accuracy by default for all the classification problems we worked on.</li><li>But the accuracy is not a good fit for this problem of multi-label since for each image we could have more than one prediction. So we need to use accuracy_multi with a threshold that will address the problem.</li></ul><blockquote><p>Note: Since the threshold for the accuracy_multi is by default 0.5, we can override the function using the partial function from python.</p></blockquote><p><strong>Example of the Learner in this case:</strong></p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>learn <span style=color:#f92672>=</span> cnn_learner(dls, resnet50, metrics<span style=color:#f92672>=</span>partial(accuracy_multi, thresh<span style=color:#f92672>=</span><span style=color:#ae81ff>0.2</span>))
</span></span><span style=display:flex><span>learn<span style=color:#f92672>.</span>fine_tune(<span style=color:#ae81ff>3</span>, base_lr<span style=color:#f92672>=</span><span style=color:#ae81ff>3e-3</span>, freeze_epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>4</span>)
</span></span></code></pre></td></tr></table></div></div><h4 id=regression>Regression<a hidden class=anchor aria-hidden=true href=#regression>#</a></h4><ul><li>A regression problem is when the output variable is a real or continuous value, such as “salary” or “weight”.</li><li>Many different models can be used, the simplest is the linear regression. It tries to fit data with the best hyper-plane which goes through the points.</li></ul><p><img loading=lazy src=/blogs/b5/img3.png alt=img3></p><ul><li>An image regression problem refers to learning from a dataset where the independent variable is an image, and the dependent variable is one or more floats.</li><li>And image regression is simply a CNN under the hood. One of the key perspective to consider while building a datablock for regression is to use pointblock instead of a category block since the labels represents coordinates.</li><li>Another important point to remember while construction the Learner is to provide the y_range=(-1,1) attribute to make sure that we give the range of the rescaled coordinates.</li></ul><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>learn <span style=color:#f92672>=</span> cnn_learner(dls, resnet18, y_range<span style=color:#f92672>=</span>(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>1</span>))
</span></span></code></pre></td></tr></table></div></div><ul><li>In the case of the regression problem, the loss that can used is MSELoss <strong>(Mean Squared Error loss)</strong>.</li><li>The MSE tells you how close a regression line is to a set of points. It does this by taking the distances from the points to the regression line (these distances are the “errors”) and squaring them.</li></ul><h4 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h4><ul><li>All the problems like single-label classification, multi-label classification & regression seems to work on basis of same model except for the loss function that changes every time.</li><li>So, we need to keep an eye on hyper parameters and loss which will effect the results.</li></ul></div><footer class=post-footer><nav class=paginav><a class=prev href=//r-c.ai/blogs/b6/ch7-dl-for-coders/><span class=title>« Prev Page</span><br><span>Chapter-7 Deep Learning for Coders with FastAI & Pytorch</span></a>
<a class=next href=//r-c.ai/blogs/b4/ch5-dl-for-coders/><span class=title>Next Page »</span><br><span>Chapter-5 Deep Learning for Coders with FastAI & Pytorch</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2023 <a href=//r-c.ai/>Ravi Chandra Veeramachaneni</a></span>
<span></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>