<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Chapter-8 Deep Learning for Coders with FastAI & Pytorch | Ravi Chandra Veeramachaneni</title><meta name=keywords content><meta name=description content="Collaborative Filtering"><meta name=author content="Ravi Chandra Veeramachaneni"><link rel=canonical href=//r-c.ai/blogs/b7/ch8-dl-for-coders/><link crossorigin=anonymous href=/assets/css/stylesheet.min.3a8b00d8b9704de6f4f33d0a113c1892c930ae073602ee85b7c5937497c98078.css integrity="sha256-OosA2LlwTeb08z0KETwYkskwrgc2Au6Ft8WTdJfJgHg=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.2840b7fccd34145847db71a290569594bdbdb00047097f75d6495d162f5d7dff.js integrity="sha256-KEC3/M00FFhH23GikFaVlL29sABHCX911kldFi9dff8=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=//r-c.ai/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=//r-c.ai/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=//r-c.ai/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=//r-c.ai/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=//r-c.ai/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-B5ZRHBFS10"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-B5ZRHBFS10",{anonymize_ip:!1})}</script><meta property="og:title" content="Chapter-8 Deep Learning for Coders with FastAI & Pytorch"><meta property="og:description" content="Collaborative Filtering"><meta property="og:type" content="article"><meta property="og:url" content="//r-c.ai/blogs/b7/ch8-dl-for-coders/"><meta property="og:image" content="//r-c.ai/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="blogs"><meta property="article:published_time" content="2021-08-11T00:00:00+00:00"><meta property="article:modified_time" content="2021-08-11T00:00:00+00:00"><meta property="og:site_name" content="RaviChandraVeeramachaneni"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="//r-c.ai/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Chapter-8 Deep Learning for Coders with FastAI & Pytorch"><meta name=twitter:description content="Collaborative Filtering"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blogs","item":"//r-c.ai/blogs/"},{"@type":"ListItem","position":2,"name":"Chapter-8 Deep Learning for Coders with FastAI \u0026 Pytorch","item":"//r-c.ai/blogs/b7/ch8-dl-for-coders/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Chapter-8 Deep Learning for Coders with FastAI \u0026 Pytorch","name":"Chapter-8 Deep Learning for Coders with FastAI \u0026 Pytorch","description":"Collaborative Filtering","keywords":[],"articleBody":"Keypoints Introduction  Recommendation systems are one of the predominant systems in market like Netflix, amazon and Walmart. And also this applies to offline systems such as which product goes in which row to capture the users. And it is one of the challenging problems. The solution for that problem is called Collaborative Filtering.  Collaborative Filtering  The Collaborative Filtering technique refers to looking at what products the current user has used or liked, find other users that have used or liked similar products, and then recommend other products that those users have used or liked. Lets looks at an example using a MovieLens dataset.  1 2 3  path = untar_data(URLs.ML_100k) ratings = pd.read_csv(path/'u.data', delimiter='\\t', header=None, names=['user','movie','rating','timestamp']) ratings.head()    With this we can now handle the data with in the ratings data frame. We can do an experiment to assign few scores to users and then get the average to multiply that with the movie score but we might end up with a match or not match. This is entirely not right because in first place we need latent factors to know how to score the movies for each user.  Latent Factors Latent factors allows us to learn how to score the products for each user set.\n Below are the steps: Step 1: Randomly initialize some parameters. These parameters will be a set of latent factors for each user and movie. We will have to decide how many to use. Step 2: Calculate the predictions. We can do this by simply taking the dot product of each movie with each user. The dot product will be very high for the ones that have a great match otherwise the product will be very low. Step 3: Calculate the loss using any loss function.  Now after this we can optimize our parameters (that is, the latent factors) using stochastic gradient descent, such as to minimize the loss or in other words the user movies recommendations. But some times due to the overfitting we can observe that the validation loss get worse and we can use a regularization technique like weight decay.    Weight Decay  Weight decay also called as L2 regularization, consists of adding sum of all the weights squared to your loss function. When we compute the gradients, it will add a contribution to them that will encourage the weights to be as small as possible and this would prevent overfitting. For a simple function like parabola, we have the following graph.   Limiting our weights from growing too much is going to complicate the training of the model, but it will yield a state where it generalizes better. To use the weight decay in fastai, just pass wd in your call to fit or fit_one_cycle. And this would yield better results.  1 2 3  model = DotProductBias(n_users, n_movies, 50) learn = Learner(dls, model, loss_func=MSELossFlat()) learn.fit_one_cycle(5, 5e-3, wd=0.1)   All the code is from the fastbook1 We can create and train a collaborative filtering model using fastAI with below code:  1  learn = collab_learner(dls, n_factors=50, y   Bootstrapping  The bootstrapping problem is a biggest challenge problem in collaborative filtering and refers to having no users to learn from. One solution would be to gather meta information from users like what genres would they like or what films they would choose from a selected few. One of the main problems in these cases would be the bias that would be introduced initially through the feedback loops. One of the approach that works better with this problem would be the Probabilistic Matrix Factorization/ (PMF) or we could apply deep learning to solve the issues related.  Deep Learning for Collaborative Filtering  As a first step, we need to concatenate the results of embedding and activations together. This gives us a matrix which we can then pass through linear layers and nonlinearities in the usual way.  Step 1: Getting the embeddings\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # Get the embeddings embs = get_emb_sz(dls)  # Class to create a model by picking up the embeddings class CollabNN(Module):  def __init__(self, user_sz, item_sz, y_range=(0,5.5), n_act=100):  self.user_factors = Embedding(*user_sz)  self.item_factors = Embedding(*item_sz)  self.layers = nn.Sequential(  nn.Linear(user_sz[1]+item_sz[1], n_act),  nn.ReLU(),  nn.Linear(n_act, 1))  self.y_range = y_range   def forward(self, x):  embs = self.user_factors(x[:,0]),self.item_factors(x[:,1])  x = self.layers(torch.cat(embs, dim=1))  return sigmoid_range(x, *self.y_range)   Step 2: Creating a model with the embeddings\nStep 3: Create a Learner and train the model\n1 2  learn = Learner(dls, model, loss_func=MSELossFlat()) learn.fit_one_cycle(5, 5e-3, wd=0.01)   Step 4: FastAI collab_learner function\n1 2  learn = collab_learner(dls, use_nn=True, y_range=(0, 5.5), layers=[100,50]) learn.fit_one_cycle(5, 5e-3, wd=0.1)    The learn.model is an object of type EmbeddingNN.  Conclusion  EmbeddingNN allow us to do something very important: we can now directly incorporate other user and movie information, date and time information, or any other information that may be relevant to the recommendation. We now have a brief understanding of how gradient descent can learn intrinsic factors or biases about items from a history of ratings which can provide some insights into the data.  Appendix   fastbook ↩︎\n   ","wordCount":"832","inLanguage":"en","datePublished":"2021-08-11T00:00:00Z","dateModified":"2021-08-11T00:00:00Z","author":{"@type":"Person","name":"Ravi Chandra Veeramachaneni"},"mainEntityOfPage":{"@type":"WebPage","@id":"//r-c.ai/blogs/b7/ch8-dl-for-coders/"},"publisher":{"@type":"Organization","name":"Ravi Chandra Veeramachaneni","logo":{"@type":"ImageObject","url":"//r-c.ai/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=//r-c.ai/ accesskey=h title="Ravi Chandra Veeramachaneni (Alt + H)"><img src=//r-c.ai/images/function.png alt=logo aria-label=logo height=35>Ravi Chandra Veeramachaneni</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=//r-c.ai/blogs/ title=Blogs><span>Blogs</span></a></li><li><a href=//r-c.ai/projects/ title=Projects><span>Projects</span></a></li><li><a href=//r-c.ai/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=//r-c.ai/>Home</a>&nbsp;»&nbsp;<a href=//r-c.ai/blogs/>Blogs</a></div><h1 class=post-title>Chapter-8 Deep Learning for Coders with FastAI & Pytorch</h1><div class=post-description>Collaborative Filtering</div><div class=post-meta><span title="2021-08-11 00:00:00 +0000 UTC">August 11, 2021</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Ravi Chandra Veeramachaneni</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#keypoints aria-label=Keypoints>Keypoints</a><ul><li><a href=#introduction aria-label=Introduction>Introduction</a></li><li><a href=#collaborative-filtering aria-label="Collaborative Filtering">Collaborative Filtering</a></li><li><a href=#latent-factors aria-label="Latent Factors">Latent Factors</a></li><li><a href=#weight-decay aria-label="Weight Decay">Weight Decay</a></li><li><a href=#bootstrapping aria-label=Bootstrapping>Bootstrapping</a></li><li><a href=#deep-learning-for-collaborative-filtering aria-label="Deep Learning for Collaborative Filtering">Deep Learning for Collaborative Filtering</a></li><li><a href=#conclusion aria-label=Conclusion>Conclusion</a></li></ul></li><li><a href=#appendix aria-label=Appendix>Appendix</a></li></ul></div></details></div><div class=post-content><h3 id=keypoints>Keypoints<a hidden class=anchor aria-hidden=true href=#keypoints>#</a></h3><h4 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h4><ul><li><strong>Recommendation systems</strong> are one of the predominant systems in market like Netflix, amazon and Walmart.</li><li>And also this applies to offline systems such as which product goes in which row to capture the users. And it is one of the challenging problems.</li><li>The solution for that problem is called <strong>Collaborative Filtering</strong>.</li></ul><h4 id=collaborative-filtering>Collaborative Filtering<a hidden class=anchor aria-hidden=true href=#collaborative-filtering>#</a></h4><ul><li>The Collaborative Filtering technique refers to looking at what products the current user has used or liked, find other users that have used or liked similar products, and then recommend other products that those users have used or liked.</li><li>Lets looks at an example using a MovieLens dataset.</li></ul><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>path <span style=color:#f92672>=</span> untar_data(URLs<span style=color:#f92672>.</span>ML_100k)
</span></span><span style=display:flex><span>ratings <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_csv(path<span style=color:#f92672>/</span><span style=color:#e6db74>&#39;u.data&#39;</span>, delimiter<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;</span><span style=color:#ae81ff>\t</span><span style=color:#e6db74>&#39;</span>, header<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>, names<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;user&#39;</span>,<span style=color:#e6db74>&#39;movie&#39;</span>,<span style=color:#e6db74>&#39;rating&#39;</span>,<span style=color:#e6db74>&#39;timestamp&#39;</span>])
</span></span><span style=display:flex><span>ratings<span style=color:#f92672>.</span>head()
</span></span></code></pre></td></tr></table></div></div><ul><li>With this we can now handle the data with in the <code>ratings</code> data frame. We can do an experiment to assign few scores to users and then get the average to multiply that with the movie score but we might end up with a match or not match.</li><li>This is entirely not right because in first place we need latent factors to know how to score the movies for each user.</li></ul><h4 id=latent-factors>Latent Factors<a hidden class=anchor aria-hidden=true href=#latent-factors>#</a></h4><p><strong>Latent factors</strong> allows us to learn how to score the products for each user set.</p><ul><li>Below are the steps:
<strong>Step 1:</strong> Randomly initialize some parameters. These parameters will be a set of latent factors for each user and movie. We will have to decide how many to use.
<strong>Step 2:</strong> Calculate the predictions. We can do this by simply taking the dot product of each movie with each user. The dot product will be very high for the ones that have a great match otherwise the product will be very low.
<strong>Step 3:</strong> Calculate the loss using any loss function.<ul><li>Now after this we can optimize our parameters (that is, the latent factors) using stochastic gradient descent, such as to minimize the loss or in other words the user movies recommendations.</li><li>But some times due to the overfitting we can observe that the validation loss get worse and we can use a regularization technique like weight decay.</li></ul></li></ul><h4 id=weight-decay>Weight Decay<a hidden class=anchor aria-hidden=true href=#weight-decay>#</a></h4><ul><li>Weight decay also called as L2 regularization, consists of adding sum of all the weights squared to your loss function.</li><li>When we compute the gradients, it will add a contribution to them that will encourage the weights to be as small as possible and this would prevent overfitting.</li><li>For a simple function like parabola, we have the following graph.</li></ul><p><img loading=lazy src=/blogs/b7/wdecay.png alt=wdecay></p><ul><li>Limiting our weights from growing too much is going to complicate the training of the model, but it will yield a state where it generalizes better.</li><li>To use the weight decay in fastai, just pass wd in your call to fit or fit_one_cycle. And this would yield better results.</li></ul><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>model <span style=color:#f92672>=</span> DotProductBias(n_users, n_movies, <span style=color:#ae81ff>50</span>)
</span></span><span style=display:flex><span>learn <span style=color:#f92672>=</span> Learner(dls, model, loss_func<span style=color:#f92672>=</span>MSELossFlat())
</span></span><span style=display:flex><span>learn<span style=color:#f92672>.</span>fit_one_cycle(<span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>5e-3</span>, wd<span style=color:#f92672>=</span><span style=color:#ae81ff>0.1</span>)
</span></span></code></pre></td></tr></table></div></div><p>All the code is from the fastbook<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></p><ul><li>We can create and train a collaborative filtering model using fastAI with below code:</li></ul><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>learn <span style=color:#f92672>=</span> collab_learner(dls, n_factors<span style=color:#f92672>=</span><span style=color:#ae81ff>50</span>, y
</span></span></code></pre></td></tr></table></div></div><h4 id=bootstrapping>Bootstrapping<a hidden class=anchor aria-hidden=true href=#bootstrapping>#</a></h4><ul><li>The bootstrapping problem is a biggest challenge problem in collaborative filtering and refers to having no users to learn from.</li><li>One solution would be to gather meta information from users like what genres would they like or what films they would choose from a selected few.</li><li>One of the main problems in these cases would be the bias that would be introduced initially through the feedback loops.</li><li>One of the approach that works better with this problem would be the Probabilistic Matrix Factorization/ (PMF) or we could apply deep learning to solve the issues related.</li></ul><h4 id=deep-learning-for-collaborative-filtering>Deep Learning for Collaborative Filtering<a hidden class=anchor aria-hidden=true href=#deep-learning-for-collaborative-filtering>#</a></h4><ul><li>As a first step, we need to concatenate the results of embedding and activations together.</li><li>This gives us a matrix which we can then pass through linear layers and nonlinearities in the usual way.</li></ul><p><strong>Step 1:</strong> Getting the embeddings</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Get the embeddings</span>
</span></span><span style=display:flex><span>embs <span style=color:#f92672>=</span> get_emb_sz(dls)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Class to create a model by picking up the embeddings</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>CollabNN</span>(Module):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, user_sz, item_sz, y_range<span style=color:#f92672>=</span>(<span style=color:#ae81ff>0</span>,<span style=color:#ae81ff>5.5</span>), n_act<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>user_factors <span style=color:#f92672>=</span> Embedding(<span style=color:#f92672>*</span>user_sz)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>item_factors <span style=color:#f92672>=</span> Embedding(<span style=color:#f92672>*</span>item_sz)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>layers <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Linear(user_sz[<span style=color:#ae81ff>1</span>]<span style=color:#f92672>+</span>item_sz[<span style=color:#ae81ff>1</span>], n_act),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Linear(n_act, <span style=color:#ae81ff>1</span>))
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>y_range <span style=color:#f92672>=</span> y_range
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x):
</span></span><span style=display:flex><span>        embs <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>user_factors(x[:,<span style=color:#ae81ff>0</span>]),self<span style=color:#f92672>.</span>item_factors(x[:,<span style=color:#ae81ff>1</span>])
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layers(torch<span style=color:#f92672>.</span>cat(embs, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>))
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> sigmoid_range(x, <span style=color:#f92672>*</span>self<span style=color:#f92672>.</span>y_range)
</span></span></code></pre></td></tr></table></div></div><p><strong>Step 2:</strong> Creating a model with the embeddings</p><p><strong>Step 3:</strong> Create a Learner and train the model</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>learn <span style=color:#f92672>=</span> Learner(dls, model, loss_func<span style=color:#f92672>=</span>MSELossFlat())
</span></span><span style=display:flex><span>learn<span style=color:#f92672>.</span>fit_one_cycle(<span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>5e-3</span>, wd<span style=color:#f92672>=</span><span style=color:#ae81ff>0.01</span>)
</span></span></code></pre></td></tr></table></div></div><p><strong>Step 4:</strong> FastAI collab_learner function</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>learn <span style=color:#f92672>=</span> collab_learner(dls, use_nn<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, y_range<span style=color:#f92672>=</span>(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>5.5</span>), layers<span style=color:#f92672>=</span>[<span style=color:#ae81ff>100</span>,<span style=color:#ae81ff>50</span>])
</span></span><span style=display:flex><span>learn<span style=color:#f92672>.</span>fit_one_cycle(<span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>5e-3</span>, wd<span style=color:#f92672>=</span><span style=color:#ae81ff>0.1</span>)
</span></span></code></pre></td></tr></table></div></div><ul><li>The learn.model is an object of type EmbeddingNN.</li></ul><h4 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h4><ul><li>EmbeddingNN allow us to do something very important: we can now directly incorporate other user and movie information, date and time information, or any other information that may be relevant to the recommendation.</li><li>We now have a brief understanding of how gradient descent can learn intrinsic factors or biases about items from a history of ratings which can provide some insights into the data.</li></ul><h3 id=appendix>Appendix<a hidden class=anchor aria-hidden=true href=#appendix>#</a></h3><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href="https://colab.research.google.com/github/fastai/fastbook/blob/master/08_collab.ipynb#scrollTo=VslC97LH7GFB">fastbook</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer class=post-footer><nav class=paginav><a class=prev href=//r-c.ai/blogs/b8/c13-dl-for-coders/><span class=title>« Prev Page</span><br><span>Chapter-13 Deep Learning for Coders with FastAI & Pytorch</span></a>
<a class=next href=//r-c.ai/blogs/b6/ch7-dl-for-coders/><span class=title>Next Page »</span><br><span>Chapter-7 Deep Learning for Coders with FastAI & Pytorch</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2023 <a href=//r-c.ai/>Ravi Chandra Veeramachaneni</a></span>
<span></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>