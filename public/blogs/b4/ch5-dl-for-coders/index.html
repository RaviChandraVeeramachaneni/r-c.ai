<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Chapter-5 Deep Learning for Coders with FastAI & Pytorch | Ravi Chandra Veeramachaneni</title><meta name=keywords content><meta name=description content="PET Breeds & Making a Model Better"><meta name=author content="Ravi Chandra Veeramachaneni"><link rel=canonical href=//r-c.ai/blogs/b4/ch5-dl-for-coders/><link crossorigin=anonymous href=/assets/css/stylesheet.min.3a8b00d8b9704de6f4f33d0a113c1892c930ae073602ee85b7c5937497c98078.css integrity="sha256-OosA2LlwTeb08z0KETwYkskwrgc2Au6Ft8WTdJfJgHg=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.2840b7fccd34145847db71a290569594bdbdb00047097f75d6495d162f5d7dff.js integrity="sha256-KEC3/M00FFhH23GikFaVlL29sABHCX911kldFi9dff8=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=//r-c.ai/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=//r-c.ai/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=//r-c.ai/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=//r-c.ai/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=//r-c.ai/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-B5ZRHBFS10"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-B5ZRHBFS10",{anonymize_ip:!1})}</script><meta property="og:title" content="Chapter-5 Deep Learning for Coders with FastAI & Pytorch"><meta property="og:description" content="PET Breeds & Making a Model Better"><meta property="og:type" content="article"><meta property="og:url" content="//r-c.ai/blogs/b4/ch5-dl-for-coders/"><meta property="og:image" content="//r-c.ai/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="blogs"><meta property="article:published_time" content="2021-07-14T00:00:00+00:00"><meta property="article:modified_time" content="2021-07-14T00:00:00+00:00"><meta property="og:site_name" content="RaviChandraVeeramachaneni"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="//r-c.ai/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Chapter-5 Deep Learning for Coders with FastAI & Pytorch"><meta name=twitter:description content="PET Breeds & Making a Model Better"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blogs","item":"//r-c.ai/blogs/"},{"@type":"ListItem","position":2,"name":"Chapter-5 Deep Learning for Coders with FastAI \u0026 Pytorch","item":"//r-c.ai/blogs/b4/ch5-dl-for-coders/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Chapter-5 Deep Learning for Coders with FastAI \u0026 Pytorch","name":"Chapter-5 Deep Learning for Coders with FastAI \u0026 Pytorch","description":"PET Breeds \u0026 Making a Model Better","keywords":[],"articleBody":"Keypoints The Keytopics in the blogpost:\n Presizing / Augmentation of Images Datablock Cross-Entropy Loss  Presizing / Augmentation of Images  The main idea behind augmenting the images is to reduce the number of computations and lossy operations. This also results in more efficient processing on the GPU. To make the above possible we need our images to have same dimensions, so they can be easily collated. Some of the challenges in doing the augmentation is that when we resize, the data could be degraded, new empty zones are introduced etc.  Overcoming stratagies\n There are around two strategies:   Resize images to relatively larger dimensions than the target training dimensions.\n  Having all the augmentation operations done at once on the GPU at end of processing rather than performing operations individually and interpolating multiple times. -Two important things to note in the below example:\n1 2 3 4 5 6  pets = DataBlock(blocks = (ImageBlock, CategoryBlock),  get_items=get_image_files,  splitter=RandomSplitter(seed=42),  get_y=using_attr(RegexLabeller(r'(.+)_\\d+.jpg$'), 'name'),  item_tfms=Resize(460),  batch_tfms=aug_transforms(size=224,* min_scale=0.75))     item_tmfs is applied to each individual image before its copied to GPU. And it ensures three things, that all images are the same size and on the training set, the crop area is chosen randomly and the validation set, the center square of the image is chosen.\n  batch_tfms is applied to a batch all at once on the GPU.\n    Datablock   A datablock is a generic container to quickly build ‘Datasets’ and ‘DataLoaders’ .\n  To build a datablock we need to know what kind of TransformBlock like a ImageBlock, CategoryBlock, which method to fetch the items like get_image_files , how to split the images, how to get the labels and any transformations to be applied.\n  The below example repeated same as above in this context is a how we create a datablock:\n1 2 3 4 5 6  pets = DataBlock(blocks = (ImageBlock, CategoryBlock),  get_items=get_image_files,  splitter=RandomSplitter(seed=42),  get_y=using_attr(RegexLabeller(r'(.+)_\\d+.jpg$'), 'name'),  item_tfms=Resize(460),  batch_tfms=aug_transforms(size=224, min_scale=0.75))     Once we have the datablock, we can get the dataloader object by just calling the dataloaders method on that datablock\n1  dls = pets.dataloaders(path/\"images\")     So to ensure that we have the datablock created properly without any errors, we can do that with the following piece of code\n1  dls.show_batch(nrows=1, ncols=3)     One of the important debugging method to learn when we have trouble creating a proper datablock is summary method. The summary method will provide very detailed stack trace\n1  pets.summary(path/\"images\")     Cross-Entropy Loss  Cross-Entropy loss is use of negative loss on probabilities. Or in simple terms Cross-Entropy loss is a combination of using the negative log likelihood on the log values of the probabilities from the softmax function.\n  The below image depicts the cross-entropy loss:  Keypoints about Cross-Entropy loss:\n The best suited loss for the Image data and a categorical outcome is Cross-Entropy loss. When we haven’t provided the loss function we want to use, the fastAI by default will pick the cross-entropy. Cross-Entropy loss works even when with multi-categories of dependent variables. And this also results in faster and more reliable training. To transform the activations of our model into predictions, we use something called the softmax activation function.  Softmax Function:\n A softmax function will ensure that all the activations in the final layer of our classification model are between 0 and 1 and they all sum up to 1. It is more or less similar to sigmoid function.   A sigmoid function when applied to single column of activations from neural network will return a column of numbers from 0 and 1. Now we are chosing softmax function since we have multi-categories and we need activations per category. If we are trying to apply the softmax function for two categories, it returns the same values as sigmoid for the first column and those subtracted from 1 for the second column.  1 2  def softmax(x):  return exp(x) / exp(x).sum(dim=1, keepdim=True)    Exponential function (exp) is defined as e**x, where e is a special number approximately equal to 2.718. It is the inverse of the natural logarithm function. Note that exp is always positive, and it increases very rapidly!\n  We need exponential since it ensures that all numbers are positive and dividing by the sum ensures that they all add up to 1. And softmax function is better at picking one class among others, so it is ideal for training. The second part of the cross-entropy loss is Log Likelihood after the softmax function.  Log Likelihood:\n Lets consider an example of having 0.99 and 0.999 as probabilities they are very close but in terms of confidence the 0.999 is more confident than 0.99. So to transform the numbers between the negative infinity and 0 to 0 and 1.   So taking the mean of the positive or negative log of our probabilities (depending on whether it’s the correct or incorrect class) gives us the negative log likelihood loss. In PyTorch, nll_loss assumes that you already took the log of the softmax, so it doesn’t actually do the logarithm for you. The CrossEntropyLoss function from pytorch exactly does the same:  Making a Model better  How to interpret a model Learning Rate Finder Unfreezing \u0026 Transfer Learning  How to interpret a model  A usual way of interpreting or evaluating the model is looking at the metrics like a confusion matrix which will show where the model is performing poorly. But one of the toughest part of interpreting confusion matrix is when it has multi-category. We can overcome this by using a FastAI convenience function like most_confused  Learning Rate Finder  One of the key points to consider when training a model would be to have a right learning rate and that can be found using the lr_find method, originally proposed by researcher Leslie Smith.  1 2  learn = cnn_learner(dls, resnet34, metrics=error_rate) lr_min,lr_steep = learn.lr_find()   Unfreezing \u0026 Transfer Learning  When training the model on a certain task, the optimizer should update the weights in the randomly added final layers. But we do not change the weights in the rest of the neural network at all. This is called freezing the pre-trained layers. When we are fine tuning the model, the fastai does two things:  Trains the randomly added layers for one epoch, with all other layers frozen. Unfreezes all of the layers, and trains them all for the number of epochs requested.   Instead of doing the fine-tuning from the library, we will also be able to do that manually. In that case we can unfreeze the layers by using the below code snippet.  Conclusion:  Cross-Entropy loss is for multi-category classification and is simply the use of negative loss on probabilities. To make our model better we can perform many steps right from data preparation which involves techniques like Pre-sizing to fine_tuning the model by fining proper learning rates. So each step has to be taken care in the whole process to yield better accuracy.  ","wordCount":"1125","inLanguage":"en","datePublished":"2021-07-14T00:00:00Z","dateModified":"2021-07-14T00:00:00Z","author":{"@type":"Person","name":"Ravi Chandra Veeramachaneni"},"mainEntityOfPage":{"@type":"WebPage","@id":"//r-c.ai/blogs/b4/ch5-dl-for-coders/"},"publisher":{"@type":"Organization","name":"Ravi Chandra Veeramachaneni","logo":{"@type":"ImageObject","url":"//r-c.ai/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=//r-c.ai/ accesskey=h title="Ravi Chandra Veeramachaneni (Alt + H)"><img src=//r-c.ai/images/function.png alt=logo aria-label=logo height=35>Ravi Chandra Veeramachaneni</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=//r-c.ai/blogs/ title=Blogs><span>Blogs</span></a></li><li><a href=//r-c.ai/projects/ title=Projects><span>Projects</span></a></li><li><a href=//r-c.ai/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=//r-c.ai/>Home</a>&nbsp;»&nbsp;<a href=//r-c.ai/blogs/>Blogs</a></div><h1 class=post-title>Chapter-5 Deep Learning for Coders with FastAI & Pytorch</h1><div class=post-description>PET Breeds & Making a Model Better</div><div class=post-meta><span title="2021-07-14 00:00:00 +0000 UTC">July 14, 2021</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;Ravi Chandra Veeramachaneni</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#keypoints aria-label=Keypoints>Keypoints</a><ul><li><a href=#presizing--augmentation-of-images aria-label="Presizing / Augmentation of Images">Presizing / Augmentation of Images</a></li><li><a href=#datablock aria-label=Datablock>Datablock</a></li><li><a href=#cross-entropy-loss aria-label="Cross-Entropy Loss">Cross-Entropy Loss</a></li></ul></li><li><a href=#making-a-model-better aria-label="Making a Model better">Making a Model better</a><ul><li><a href=#how-to-interpret-a-model aria-label="How to interpret a model">How to interpret a model</a></li><li><a href=#learning-rate-finder aria-label="Learning Rate Finder">Learning Rate Finder</a></li><li><a href=#unfreezing--transfer-learning aria-label="Unfreezing &amp;amp; Transfer Learning">Unfreezing & Transfer Learning</a></li><li><a href=#conclusion aria-label=Conclusion:>Conclusion:</a></li></ul></li></ul></div></details></div><div class=post-content><h3 id=keypoints>Keypoints<a hidden class=anchor aria-hidden=true href=#keypoints>#</a></h3><p>The Keytopics in the blogpost:</p><ul><li>Presizing / Augmentation of Images</li><li>Datablock</li><li>Cross-Entropy Loss</li></ul><h4 id=presizing--augmentation-of-images>Presizing / Augmentation of Images<a hidden class=anchor aria-hidden=true href=#presizing--augmentation-of-images>#</a></h4><ul><li>The main idea behind augmenting the images is to reduce the number of computations and lossy operations. This also results in more efficient processing on the GPU.</li><li>To make the above possible we need our images to have same dimensions, so they can be easily collated.</li><li>Some of the challenges in doing the augmentation is that when we resize, the data could be degraded, new empty zones are introduced etc.</li></ul><p><img loading=lazy src=/blogs/b4/dog.png alt=dog></p><p><strong>Overcoming stratagies</strong></p><ul><li>There are around two strategies:<ul><li><p>Resize images to relatively larger dimensions than the target training dimensions.</p></li><li><p>Having all the augmentation operations done at once on the GPU at end of processing rather than performing operations individually and interpolating multiple times.
-Two important things to note in the below example:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">5
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">6
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>pets <span style=color:#f92672>=</span> DataBlock(blocks <span style=color:#f92672>=</span> (ImageBlock, CategoryBlock),
</span></span><span style=display:flex><span>            get_items<span style=color:#f92672>=</span>get_image_files, 
</span></span><span style=display:flex><span>            splitter<span style=color:#f92672>=</span>RandomSplitter(seed<span style=color:#f92672>=</span><span style=color:#ae81ff>42</span>),
</span></span><span style=display:flex><span>            get_y<span style=color:#f92672>=</span>using_attr(RegexLabeller(<span style=color:#e6db74>r</span><span style=color:#e6db74>&#39;(.+)_\d+.jpg$&#39;</span>), <span style=color:#e6db74>&#39;name&#39;</span>),
</span></span><span style=display:flex><span>            item_tfms<span style=color:#f92672>=</span>Resize(<span style=color:#ae81ff>460</span>),
</span></span><span style=display:flex><span>            batch_tfms<span style=color:#f92672>=</span>aug_transforms(size<span style=color:#f92672>=</span><span style=color:#ae81ff>224</span>,<span style=color:#f92672>*</span> min_scale<span style=color:#f92672>=</span><span style=color:#ae81ff>0.75</span>))
</span></span></code></pre></td></tr></table></div></div></li><li><p><strong>item_tmfs</strong> is applied to each individual image before its copied to GPU. And it ensures three things, that all images are the same size and on the training set, the crop area is chosen randomly and the validation set, the center square of the image is chosen.</p></li><li><p><strong>batch_tfms</strong> is applied to a batch all at once on the GPU.</p></li></ul></li></ul><h4 id=datablock>Datablock<a hidden class=anchor aria-hidden=true href=#datablock>#</a></h4><ul><li><p>A datablock is a generic container to quickly build ‘Datasets’ and ‘DataLoaders’ .</p></li><li><p>To build a datablock we need to know what kind of TransformBlock like a ImageBlock, CategoryBlock, which method to fetch the items like get_image_files , how to split the images, how to get the labels and any transformations to be applied.</p></li><li><p>The below example repeated same as above in this context is a how we create a datablock:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">5
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">6
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>pets <span style=color:#f92672>=</span> DataBlock(blocks <span style=color:#f92672>=</span> (ImageBlock, CategoryBlock),
</span></span><span style=display:flex><span>              get_items<span style=color:#f92672>=</span>get_image_files, 
</span></span><span style=display:flex><span>              splitter<span style=color:#f92672>=</span>RandomSplitter(seed<span style=color:#f92672>=</span><span style=color:#ae81ff>42</span>),
</span></span><span style=display:flex><span>              get_y<span style=color:#f92672>=</span>using_attr(RegexLabeller(<span style=color:#e6db74>r</span><span style=color:#e6db74>&#39;(.+)_\d+.jpg$&#39;</span>), <span style=color:#e6db74>&#39;name&#39;</span>),
</span></span><span style=display:flex><span>              item_tfms<span style=color:#f92672>=</span>Resize(<span style=color:#ae81ff>460</span>),
</span></span><span style=display:flex><span>              batch_tfms<span style=color:#f92672>=</span>aug_transforms(size<span style=color:#f92672>=</span><span style=color:#ae81ff>224</span>, min_scale<span style=color:#f92672>=</span><span style=color:#ae81ff>0.75</span>))
</span></span></code></pre></td></tr></table></div></div></li><li><p>Once we have the datablock, we can get the dataloader object by just calling the dataloaders method on that datablock</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>dls <span style=color:#f92672>=</span> pets<span style=color:#f92672>.</span>dataloaders(path<span style=color:#f92672>/</span><span style=color:#e6db74>&#34;images&#34;</span>)
</span></span></code></pre></td></tr></table></div></div></li><li><p>So to ensure that we have the datablock created properly without any errors, we can do that with the following piece of code</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>dls<span style=color:#f92672>.</span>show_batch(nrows<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, ncols<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>)
</span></span></code></pre></td></tr></table></div></div></li><li><p>One of the important debugging method to learn when we have trouble creating a proper datablock is summary method. The summary method will provide very detailed stack trace</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>pets<span style=color:#f92672>.</span>summary(path<span style=color:#f92672>/</span><span style=color:#e6db74>&#34;images&#34;</span>)
</span></span></code></pre></td></tr></table></div></div></li></ul><h4 id=cross-entropy-loss>Cross-Entropy Loss<a hidden class=anchor aria-hidden=true href=#cross-entropy-loss>#</a></h4><blockquote><p>Cross-Entropy loss is use of negative loss on probabilities. Or in simple terms Cross-Entropy loss is a combination of using the negative log likelihood on the log values of the probabilities from the softmax function.</p></blockquote><ul><li>The below image depicts the cross-entropy loss:</li></ul><p><img loading=lazy src=/blogs/b4/ce-loss.png alt=ce-loss></p><p><strong>Keypoints about Cross-Entropy loss:</strong></p><ul><li>The best suited loss for the Image data and a categorical outcome is Cross-Entropy loss. When we haven’t provided the loss function we want to use, the fastAI by default will pick the cross-entropy.</li><li>Cross-Entropy loss works even when with multi-categories of dependent variables.</li><li>And this also results in faster and more reliable training.</li><li>To transform the activations of our model into predictions, we use something called the softmax activation function.</li></ul><p><strong>Softmax Function:</strong></p><ul><li>A softmax function will ensure that all the activations in the final layer of our classification model are between 0 and 1 and they all sum up to 1.</li><li>It is more or less similar to sigmoid function.</li></ul><p><img loading=lazy src=/blogs/b4/sigmoid.png alt=sigmoid></p><ul><li>A sigmoid function when applied to single column of activations from neural network will return a column of numbers from 0 and 1. Now we are chosing softmax function since we have multi-categories and we need activations per category.</li><li>If we are trying to apply the softmax function for two categories, it returns the same values as sigmoid for the first column and those subtracted from 1 for the second column.</li></ul><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>softmax</span>(x): 
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> exp(x) <span style=color:#f92672>/</span> exp(x)<span style=color:#f92672>.</span>sum(dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, keepdim<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span></code></pre></td></tr></table></div></div><blockquote><p>Exponential function (exp) is defined as e**x, where e is a special number approximately equal to 2.718. It is the inverse of the natural logarithm function. Note that exp is always positive, and it increases very rapidly!</p></blockquote><ul><li>We need exponential since it ensures that all numbers are positive and dividing by the sum ensures that they all add up to 1.</li><li>And softmax function is better at picking one class among others, so it is ideal for training.</li><li>The second part of the cross-entropy loss is Log Likelihood after the softmax function.</li></ul><p><strong>Log Likelihood:</strong></p><ul><li>Lets consider an example of having 0.99 and 0.999 as probabilities they are very close but in terms of confidence the 0.999 is more confident than 0.99. So to transform the numbers between the negative infinity and 0 to 0 and 1.</li></ul><p><img loading=lazy src=/blogs/b4/log.png alt=log></p><ul><li>So taking the mean of the positive or negative log of our probabilities (depending on whether it’s the correct or incorrect class) gives us the negative log likelihood loss. In PyTorch, nll_loss assumes that you already took the log of the softmax, so it doesn’t actually do the logarithm for you.</li><li>The CrossEntropyLoss function from pytorch exactly does the same:</li></ul><p><img loading=lazy src=/blogs/b4/pytorch-ce.png alt=pytorch-ce></p><h3 id=making-a-model-better>Making a Model better<a hidden class=anchor aria-hidden=true href=#making-a-model-better>#</a></h3><ul><li>How to interpret a model</li><li>Learning Rate Finder</li><li>Unfreezing & Transfer Learning</li></ul><h4 id=how-to-interpret-a-model>How to interpret a model<a hidden class=anchor aria-hidden=true href=#how-to-interpret-a-model>#</a></h4><ul><li>A usual way of interpreting or evaluating the model is looking at the metrics like a confusion matrix which will show where the model is performing poorly.</li><li>But one of the toughest part of interpreting confusion matrix is when it has multi-category.</li><li>We can overcome this by using a FastAI convenience function like most_confused</li></ul><p><img loading=lazy src=/blogs/b4/in-model.png alt=in-model></p><h4 id=learning-rate-finder>Learning Rate Finder<a hidden class=anchor aria-hidden=true href=#learning-rate-finder>#</a></h4><ul><li>One of the key points to consider when training a model would be to have a right learning rate and that can be found using the lr_find method, originally proposed by researcher Leslie Smith.</li></ul><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>learn <span style=color:#f92672>=</span> cnn_learner(dls, resnet34, metrics<span style=color:#f92672>=</span>error_rate)
</span></span><span style=display:flex><span>lr_min,lr_steep <span style=color:#f92672>=</span> learn<span style=color:#f92672>.</span>lr_find()
</span></span></code></pre></td></tr></table></div></div><p><img loading=lazy src=/blogs/b4/lr-rate.png alt=lr-rate></p><h4 id=unfreezing--transfer-learning>Unfreezing & Transfer Learning<a hidden class=anchor aria-hidden=true href=#unfreezing--transfer-learning>#</a></h4><ul><li>When training the model on a certain task, the optimizer should update the weights in the randomly added final layers. But we do not change the weights in the rest of the neural network at all. This is called freezing the pre-trained layers.</li><li>When we are fine tuning the model, the fastai does two things:<ul><li>Trains the randomly added layers for one epoch, with all other layers frozen.</li><li>Unfreezes all of the layers, and trains them all for the number of epochs requested.</li></ul></li><li>Instead of doing the fine-tuning from the library, we will also be able to do that manually. In that case we can unfreeze the layers by using the below code snippet.</li></ul><h4 id=conclusion>Conclusion:<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h4><ul><li>Cross-Entropy loss is for multi-category classification and is simply the use of negative loss on probabilities.</li><li>To make our model better we can perform many steps right from data preparation which involves techniques like Pre-sizing to fine_tuning the model by fining proper learning rates. So each step has to be taken care in the whole process to yield better accuracy.</li></ul></div><footer class=post-footer><nav class=paginav><a class=prev href=//r-c.ai/blogs/b5/ch6-dl-for-coders/><span class=title>« Prev Page</span><br><span>Chapter-6 Deep Learning for Coders with FastAI & Pytorch</span></a>
<a class=next href=//r-c.ai/blogs/b3/ch4-dl-for-coders/><span class=title>Next Page »</span><br><span>Chapter-4 Deep Learning for Coders with FastAI & Pytorch</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2023 <a href=//r-c.ai/>Ravi Chandra Veeramachaneni</a></span>
<span></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>