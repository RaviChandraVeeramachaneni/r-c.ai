<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Chapter-1 Deep Learning for Coders with FastAI & Pytorch | Ravi Chandra Veeramachaneni</title><meta name=keywords content><meta name=description content="Keypoints  Deep Learning(DL) is for everyone and it can be learned without starting with math. DL is good at lot of tasks such as Natural Language Processing, Computer Vision etc. It’s an technique to extract and transform data and it uses multiple layers of neural networks. Each of these layers take input from previous layers and refines them further. Over the time, the layers improve accuracy & minimize error. And the network learns to perform a specific task."><meta name=author content="Ravi Chandra Veeramachaneni"><link rel=canonical href=//r-c.ai/blogs/b1/ch1-dl-for-coders/><link crossorigin=anonymous href=/assets/css/stylesheet.min.3a8b00d8b9704de6f4f33d0a113c1892c930ae073602ee85b7c5937497c98078.css integrity="sha256-OosA2LlwTeb08z0KETwYkskwrgc2Au6Ft8WTdJfJgHg=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.2840b7fccd34145847db71a290569594bdbdb00047097f75d6495d162f5d7dff.js integrity="sha256-KEC3/M00FFhH23GikFaVlL29sABHCX911kldFi9dff8=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=//r-c.ai/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=//r-c.ai/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=//r-c.ai/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=//r-c.ai/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=//r-c.ai/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-B5ZRHBFS10"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-B5ZRHBFS10",{anonymize_ip:!1})}</script><meta property="og:title" content="Chapter-1 Deep Learning for Coders with FastAI & Pytorch"><meta property="og:description" content="Keypoints  Deep Learning(DL) is for everyone and it can be learned without starting with math. DL is good at lot of tasks such as Natural Language Processing, Computer Vision etc. It’s an technique to extract and transform data and it uses multiple layers of neural networks. Each of these layers take input from previous layers and refines them further. Over the time, the layers improve accuracy & minimize error. And the network learns to perform a specific task."><meta property="og:type" content="article"><meta property="og:url" content="//r-c.ai/blogs/b1/ch1-dl-for-coders/"><meta property="og:image" content="//r-c.ai/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="blogs"><meta property="article:published_time" content="2021-06-09T00:00:00+00:00"><meta property="article:modified_time" content="2021-06-09T00:00:00+00:00"><meta property="og:site_name" content="RaviChandraVeeramachaneni"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="//r-c.ai/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Chapter-1 Deep Learning for Coders with FastAI & Pytorch"><meta name=twitter:description content="Keypoints  Deep Learning(DL) is for everyone and it can be learned without starting with math. DL is good at lot of tasks such as Natural Language Processing, Computer Vision etc. It’s an technique to extract and transform data and it uses multiple layers of neural networks. Each of these layers take input from previous layers and refines them further. Over the time, the layers improve accuracy & minimize error. And the network learns to perform a specific task."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blogs","item":"//r-c.ai/blogs/"},{"@type":"ListItem","position":2,"name":"Chapter-1 Deep Learning for Coders with FastAI \u0026 Pytorch","item":"//r-c.ai/blogs/b1/ch1-dl-for-coders/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Chapter-1 Deep Learning for Coders with FastAI \u0026 Pytorch","name":"Chapter-1 Deep Learning for Coders with FastAI \u0026 Pytorch","description":"Keypoints  Deep Learning(DL) is for everyone and it can be learned without starting with math. DL is good at lot of tasks such as Natural Language Processing, Computer Vision etc. It’s an technique to extract and transform data and it uses multiple layers of neural networks. Each of these layers take input from previous layers and refines them further. Over the time, the layers improve accuracy \u0026amp; minimize error. And the network learns to perform a specific task.","keywords":[],"articleBody":"Keypoints  Deep Learning(DL) is for everyone and it can be learned without starting with math. DL is good at lot of tasks such as Natural Language Processing, Computer Vision etc. It’s an technique to extract and transform data and it uses multiple layers of neural networks. Each of these layers take input from previous layers and refines them further. Over the time, the layers improve accuracy \u0026 minimize error. And the network learns to perform a specific task. Libraries like Fastai or pytorch may be outdated so its better to always learn the low level concepts \u0026 algorithms underlying. Machine Learning - Training of programs, developed by allowing a computer to learn from its experience, rather than manually coding the individual steps. Deep Learning - Its the more general discipline of machine learning. A general program takes inputs \u0026 outputs results. In machine learning the program is called Model since it takes inputs \u0026 weights. A Machine Learning program outputs results based on inputs \u0026 weights. The model can have a different outputs for same inputs with different set of weights. A Model is called trained when the weight assignment is final.  Important Note - Start\n  A Trained Model can be treated like a regular computer program. Neural Network - A flexible mathematical function that can be used to solve any problem.\n  In Neural networks, the way to automatically update weights for any given task is called “Stochastic Gradient Descent”. This process of going back and updating weights is called Back-propagation.\n   The functional form of the model is called architecture. Weights / Parameters are interchangeable words. The actual results of the model are called “Predictions” and they are calculated from the independent variable, which is the data not including the labels. The way our model is performing, that measure is called “Loss”. In a dataset we have 2 things, 1. the Images \u0026 2. the Labels. The labels are the categories or classes like cat or dog. The Labels are also called “Targets or Dependent variables” and the loss is dependent on the labels as well, not just solely on the predictions. Some of the limitations are: Model does not exist without data, model learns from the input data and the outcome is “predictions”. Some of the key functions/points learned out of fastAI library:   untar_data() - A function that takes the url of the data set, downloads it and unzip it. In FastAI for Images, we have functions starting with Images like ImageDataLoaders and for text we have functions starting with Text like TextDataLoaders. In FastAI we have 2 types of transforms, Item transforms(item_tfms), and the other is Batch transforms(batch_tfms). The item tranformation operates on each item / input image to resize them to a similar size and the batch transform operates on the batches of items and pass them to the GPU(s) for training. And “EPOCH” is a one pass through, of all the images in training. And the process of the model learning in each epoch is called “Model Fitting”.  First Model as described in chapter 1\n1 2 3 4 5 6 7 8 9 10   from fastai.vision.all import *  path = untar_data(URLs.PETS)/'images'   def is_cat(x): return x[0].isupper()  dls = ImageDataLoaders.from_name_func(  path, get_image_files(path), valid_pct=0.2, seed=42,  label_func=is_cat, item_tfms=Resize(224))   learn = cnn_learner(dls, resnet34, metrics=error_rate)  learn.fine_tune(1)    ImageDataLoaders function (Understanding each parameter)  label_func: Takes a function as input, which is used for the classifying the outcome like Yes/No. Example : def is_cat(): return x[0].isupper(). A specific example since in this dataset of cats vs dogs the cats start with Uppercase and dogs with lowercase. item_tfms: Item Transformations - The item transform takes an Resize(224) input and transforms each image aka item into 224x224 size from what ever the original size of the each image might be. valid_pct: A valid percentage is required to split the data into training \u0026 validation. A validation set is critical for testing the model for what it has learned in the training phase from rest of the training data.    Image credits1 Based on the predictions on the validation set(Hold-on set) , we can measure the performance of the model and also avoid overfitting. seed() - sets the seed value so that we get the same validation set every time we run the Model. cnn_learner function: A Convolutional Neural Network is a type of model that is best for vision based tasks and learns from the data. This method takes a particular type of architecture for example resnet34(34-layers) which is a mathematical model that can classify things. Overfitting - A concept thats occurs when the model fits exactly against the training data. In other words if the model tries to fit too closely to each point in the data, then the model becomes “overfitted”. And because of this overfitting model will be unable to generalize well to new data. Metrics - A metric is a function that measures how good the model predictions are comparing the output with actual label and is called Accuracy. Loss vs Metrics - A Loss is used by model for improving the training performance by updating weights using methods like SGD(using back-propagation) and Metrics is just a measure for us to know the performance of the model. Transfer Learning - Using a pre-trained dataset like IMAGENET for classifying a different task. A IMAGENET is an original dataset with 1M images used for vision tasks. Pre-trained weights - We use the weights from the pre-trained model and use that for our task. In this context the last layer is just updated with the new head (head - is our categories like cat \u0026 dog). That last layer replaced originally contained 1000 categories and now has just 2 categories. Fine Tuning - Training the model on a general dataset \u0026 then training it on our own dataset. This is where we are using the pre-trained weights for all the layers unaltered except for the last layer(head). The process of retaining the model stem(pre-trained weights) and just training the new head is called Fine Tuning. And it’s a Transfer learning technique.    The fine tuning in Fast AI has 2 passes, in the first pass the pre-trained stem is frozen and the Head(the last layer / our data layer) is trained. And in second pass the stem \u0026 the trained head from first pass is again trained but at different speeds (trained head is again trained faster than the stem in this phase).\n  learn.fine_tune() - The number of times we want that pass to go through. If the no.of.epochs = 1, then each pass goes exactly once in the fine tuning steps. The Higher the epochs, the model learns better.\n  Model Learning - Demystifying Model Learning\n Each layer of the Model (each layer of the neural network : example 34 layers in restnet34) learns differently \u0026 different kinds of input patterns and by the last layer the model will be able to actually understand the task that we are aiming for. The best example of the how model learns after each layer is described in the paper by Matthew D. Zeiler \u0026 Rob Fergus2   One of the Key idea in Computer Vision is to use the Pretrained weights since learning with lots of data in the stem gives the knowledge of shapes, sizes and all sort of information for the neural network and the last layer which is trained on our data knows how to recognize cats vs dogs. This also reduces lot of compute. Image Recognition can also handle non-image related tasks by converting the graphs \u0026 charts into images and then try identifying the patterns from those images.    Appendix   All Image credits to AmanArora from FastAI book reading session ↩︎\n The above paper is from Matthew D. Zeiler \u0026 Rob Fergus. ↩︎\n   ","wordCount":"1285","inLanguage":"en","datePublished":"2021-06-09T00:00:00Z","dateModified":"2021-06-09T00:00:00Z","author":{"@type":"Person","name":"Ravi Chandra Veeramachaneni"},"mainEntityOfPage":{"@type":"WebPage","@id":"//r-c.ai/blogs/b1/ch1-dl-for-coders/"},"publisher":{"@type":"Organization","name":"Ravi Chandra Veeramachaneni","logo":{"@type":"ImageObject","url":"//r-c.ai/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=//r-c.ai/ accesskey=h title="Ravi Chandra Veeramachaneni (Alt + H)"><img src=//r-c.ai/images/function.png alt=logo aria-label=logo height=35>Ravi Chandra Veeramachaneni</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=//r-c.ai/blogs/ title=Blogs><span>Blogs</span></a></li><li><a href=//r-c.ai/projects/ title=Projects><span>Projects</span></a></li><li><a href=//r-c.ai/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=//r-c.ai/>Home</a>&nbsp;»&nbsp;<a href=//r-c.ai/blogs/>Blogs</a></div><h1 class=post-title>Chapter-1 Deep Learning for Coders with FastAI & Pytorch</h1><div class=post-meta><span title="2021-06-09 00:00:00 +0000 UTC">June 9, 2021</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;Ravi Chandra Veeramachaneni</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#keypoints aria-label=Keypoints>Keypoints</a></li><li><a href=#appendix aria-label=Appendix>Appendix</a></li></ul></div></details></div><div class=post-content><h3 id=keypoints>Keypoints<a hidden class=anchor aria-hidden=true href=#keypoints>#</a></h3><ul><li>Deep Learning(DL) is for everyone and it can be learned without starting with math.</li><li>DL is good at lot of tasks such as Natural Language Processing, Computer Vision etc.</li><li>It’s an technique to extract and transform data and it uses multiple layers of neural networks.</li><li>Each of these layers take input from previous layers and refines them further. Over the time, the layers improve accuracy & minimize error. And the network learns to perform a specific task.</li><li>Libraries like Fastai or pytorch may be outdated so its better to always learn the low level concepts & algorithms underlying.</li><li>Machine Learning - Training of programs, developed by allowing a computer to learn from its experience, rather than manually coding the individual steps.</li><li>Deep Learning - Its the more general discipline of machine learning.</li><li>A general program takes inputs & outputs results.</li><li>In machine learning the program is called Model since it takes inputs & weights.</li><li>A Machine Learning program outputs results based on inputs & weights. The model can have a different outputs for same inputs with different set of weights.</li><li>A Model is called trained when the weight assignment is final.</li></ul><p><strong>Important Note - Start</strong></p><ol><li><p>A Trained Model can be treated like a regular computer program.
Neural Network - A flexible mathematical function that can be used to solve any problem.</p></li><li><p>In Neural networks, the way to automatically update weights for any given task is called “Stochastic Gradient Descent”. This process of going back and updating weights is called Back-propagation.</p></li></ol><ul><li>The functional form of the model is called <strong>architecture</strong>.</li><li>Weights / Parameters are interchangeable words.</li><li>The actual results of the model are called “Predictions” and they are calculated from the independent variable, which is the data not including the labels.</li><li>The way our model is performing, that measure is called “Loss”.
In a dataset we have 2 things, 1. the Images & 2. the Labels. The labels are the categories or classes like cat or dog.</li><li>The Labels are also called “Targets or Dependent variables” and the loss is dependent on the labels as well, not just solely on the predictions.</li><li>Some of the limitations are: Model does not exist without data, model learns from the input data and the outcome is “predictions”.</li><li>Some of the key functions/points learned out of fastAI library:</li></ul><ol><li>untar_data() - A function that takes the url of the data set, downloads it and unzip it.
In FastAI for Images, we have functions starting with Images like ImageDataLoaders and for text we have functions starting with Text like TextDataLoaders.</li><li>In FastAI we have 2 types of transforms, Item transforms(item_tfms), and the other is Batch transforms(batch_tfms). The item tranformation operates on each item / input image to resize them to a similar size and the batch transform operates on the batches of items and pass them to the GPU(s) for training.</li><li>And “EPOCH” is a one pass through, of all the images in training. And the process of the model learning in each epoch is called “Model Fitting”.</li></ol><p>First Model as described in chapter 1</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>  <span style=color:#f92672>from</span> fastai.vision.all <span style=color:#f92672>import</span> <span style=color:#f92672>*</span>
</span></span><span style=display:flex><span>  path <span style=color:#f92672>=</span> untar_data(URLs<span style=color:#f92672>.</span>PETS)<span style=color:#f92672>/</span><span style=color:#e6db74>&#39;images&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>is_cat</span>(x): <span style=color:#66d9ef>return</span> x[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>.</span>isupper()
</span></span><span style=display:flex><span>  dls <span style=color:#f92672>=</span> ImageDataLoaders<span style=color:#f92672>.</span>from_name_func(
</span></span><span style=display:flex><span>      path, get_image_files(path), valid_pct<span style=color:#f92672>=</span><span style=color:#ae81ff>0.2</span>, seed<span style=color:#f92672>=</span><span style=color:#ae81ff>42</span>,
</span></span><span style=display:flex><span>      label_func<span style=color:#f92672>=</span>is_cat, item_tfms<span style=color:#f92672>=</span>Resize(<span style=color:#ae81ff>224</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  learn <span style=color:#f92672>=</span> cnn_learner(dls, resnet34, metrics<span style=color:#f92672>=</span>error_rate)
</span></span><span style=display:flex><span>  learn<span style=color:#f92672>.</span>fine_tune(<span style=color:#ae81ff>1</span>)
</span></span></code></pre></td></tr></table></div></div><ul><li><strong>ImageDataLoaders function</strong> (Understanding each parameter)<ul><li>label_func: Takes a function as input, which is used for the classifying the outcome like Yes/No.</li><li>Example : def is_cat(): return x[0].isupper(). A specific example since in this dataset of cats vs dogs the cats start with Uppercase and dogs with lowercase.</li><li>item_tfms: Item Transformations - The item transform takes an Resize(224) input and transforms each image aka item into 224x224 size from what ever the original size of the each image might be.</li><li>valid_pct: A valid percentage is required to split the data into training & validation. A validation set is critical for testing the model for what it has learned in the training phase from rest of the training data.</li></ul></li></ul><p><img loading=lazy src=/blogs/b1/trset.png alt=trset>
Image credits<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></p><ul><li>Based on the predictions on the validation set(Hold-on set) , we can measure the performance of the model and also avoid overfitting.</li><li>seed() - sets the seed value so that we get the same validation set every time we run the Model.</li><li><strong>cnn_learner function:</strong> A Convolutional Neural Network is a type of model that is best for vision based tasks and learns from the data. This method takes a particular type of architecture for example resnet34(34-layers) which is a mathematical model that can classify things.</li><li><strong>Overfitting</strong> - A concept thats occurs when the model fits exactly against the training data. In other words if the model tries to fit too closely to each point in the data, then the model becomes “overfitted”. And because of this overfitting model will be unable to generalize well to new data.</li><li><strong>Metrics</strong> - A metric is a function that measures how good the model predictions are comparing the output with actual label and is called Accuracy.</li><li><strong>Loss vs Metrics</strong> - A Loss is used by model for improving the training performance by updating weights using methods like SGD(using back-propagation) and Metrics is just a measure for us to know the performance of the model.</li><li><strong>Transfer Learning</strong> - Using a pre-trained dataset like IMAGENET for classifying a different task. A IMAGENET is an original dataset with 1M images used for vision tasks.</li><li><strong>Pre-trained weights</strong> - We use the weights from the pre-trained model and use that for our task. In this context the last layer is just updated with the new head (head - is our categories like cat & dog). That last layer replaced originally contained 1000 categories and now has just 2 categories.</li><li><strong>Fine Tuning</strong> - Training the model on a general dataset & then training it on our own dataset. This is where we are using the pre-trained weights for all the layers unaltered except for the last layer(head). The process of retaining the model stem(pre-trained weights) and just training the new head is called Fine Tuning. And it’s a Transfer learning technique.</li></ul><p><img loading=lazy src=/blogs/b1/fine_tuning.png alt=fine_tuning></p><ul><li><p>The fine tuning in Fast AI has 2 passes, in the first pass the pre-trained stem is frozen and the Head(the last layer / our data layer) is trained. And in second pass the stem & the trained head from first pass is again trained but at different speeds (trained head is again trained faster than the stem in this phase).</p></li><li><p>learn.fine_tune() - The number of times we want that pass to go through. If the no.of.epochs = 1, then each pass goes exactly once in the fine tuning steps. The Higher the epochs, the model learns better.</p></li><li><p><strong>Model Learning</strong> - Demystifying Model Learning</p><ul><li>Each layer of the Model (each layer of the neural network : example 34 layers in restnet34) learns differently & different kinds of input patterns and by the last layer the model will be able to actually understand the task that we are aiming for.</li><li>The best example of the how model learns after each layer is described in the paper by
Matthew D. Zeiler & Rob Fergus<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></li></ul><ul><li>One of the Key idea in Computer Vision is to use the Pretrained weights since learning with lots of data in the stem gives the knowledge of shapes, sizes and all sort of information for the neural network and the last layer which is trained on our data knows how to recognize cats vs dogs. This also reduces lot of compute.</li><li>Image Recognition can also handle non-image related tasks by converting the graphs & charts into images and then try identifying the patterns from those images.</li></ul></li></ul><h3 id=appendix>Appendix<a hidden class=anchor aria-hidden=true href=#appendix>#</a></h3><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>All Image credits to AmanArora from FastAI book reading session&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>The above paper is from <a href=https://arxiv.org/pdf/1311.2901.pdf>Matthew D. Zeiler & Rob Fergus</a>.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer class=post-footer><nav class=paginav><a class=prev href=//r-c.ai/blogs/b2/ch2-dl-for-coders/><span class=title>« Prev Page</span><br><span>Chapter-2 Deep Learning for Coders with FastAI & Pytorch</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2023 <a href=//r-c.ai/>Ravi Chandra Veeramachaneni</a></span>
<span></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>